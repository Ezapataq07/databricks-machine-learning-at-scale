{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2c16b9-1a68-4783-88ce-677729734e78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering matplotlib shap\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0dbc10f-82ae-47be-b345-db046f88e244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pyspark.sql.functions as f\n",
    "# from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# url = \"https://raw.githubusercontent.com/Ezapataq07/databricks-machine-learning-at-scale/refs/heads/main/machine-learning-at-scale-1.2.2/FeatureStore/diabetes.csv\"\n",
    "\n",
    "# pdf = pd.read_csv(url)\n",
    "# pdf.columns = [col.replace('.','') for col in pdf.columns]\n",
    "# df = spark.createDataFrame(pdf)\n",
    "\n",
    "# df = df.withColumn('target', f.when(\n",
    "#                         f.col('glyhb') >= 6.5, 1\n",
    "#                         ). otherwise(\n",
    "#                             0\n",
    "#                         ))\n",
    "\n",
    "# df = df.withColumn('gender', f.when(\n",
    "#                                 f.col('gender') == 'female', 1\n",
    "#                             ). otherwise(\n",
    "#                                 0\n",
    "# ))\n",
    "\n",
    "\n",
    "# df.write.format('delta').mode('overwrite').saveAsTable('workspace.ml_training.diabetes_dataset')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b403603-effe-4d78-b7e7-6a5a0bc26739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Create the feature table\n",
    "# from databricks.feature_engineering import FeatureEngineeringClient\n",
    "# fe = FeatureEngineeringClient()\n",
    "\n",
    "# fe.create_table(\n",
    "#     name = 'workspace.ml_training.diabetes_features',\n",
    "#     primary_keys = ['id'],\n",
    "#     df = df.drop('target','location','frame'),\n",
    "#     description = 'Diabetes features'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "296e55e4-0587-4aa7-9998-e6a428764ee2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM workspace.ml_training.diabetes_dataset\")\n",
    "\n",
    "# Use the features table with MLFLow\n",
    "\n",
    "import mlflow \n",
    "\n",
    "feature_dataset = mlflow.data.load_delta(table_name = 'workspace.ml_training.diabetes_features', name = 'diabetes_binary')\n",
    "\n",
    "feature_data_pd = feature_dataset.df.join(df.select('id','target'),on='id',how='left').toPandas()\n",
    "feature_data_pd = feature_data_pd.drop('id', axis=1)\n",
    "feature_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e3415fe-7b6c-4c80-8c61-15818e744067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for column in feature_data_pd.columns:\n",
    "    feature_data_pd[column] = feature_data_pd[column].astype('double')\n",
    "\n",
    "print(feature_data_pd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3ffdca-5d98-4d4f-9838-657c7f441822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train / test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = 'target'\n",
    "\n",
    "X = feature_data_pd.drop(target_col, axis=1)\n",
    "y = feature_data_pd[target_col]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983382b3-5ba5-4ade-a0f2-531304854158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit and Log the model\n",
    "dtc_params = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 50,\n",
    "    'min_samples_split': 20,\n",
    "    'min_samples_leaf': 5\n",
    "}\n",
    "\n",
    "# Register models in UC\n",
    "\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Workspace/Users/emanuel.zapata@datalytics.com/ModelTrackingMLFlow\")\n",
    "\n",
    "# turn off autologging\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "model_name = f\"workspace.ml_training.diabetes_model\"\n",
    "\n",
    "# start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Model Tracking Demo\") as run:\n",
    "    # log the dataset\n",
    "    mlflow.log_input(feature_dataset, context=\"source\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_train, source=feature_dataset.source), context=\"training\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_test, source=feature_dataset.source), context=\"test\")\n",
    "\n",
    "    # log our parameters \n",
    "    mlflow. log_params(dtc_params)\n",
    "\n",
    "    # fit our model\n",
    "    dtc = DecisionTreeClassifier(**dtc_params)\n",
    "    dtc_mdl=dtc.fit(X_train, y_train)\n",
    "\n",
    "    # define model signiture\n",
    "    signature = infer_signature(X, y)\n",
    "\n",
    "    # log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model = dtc_mdl,\n",
    "        artifact_path=\"model-artifacts\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name)\n",
    "\n",
    "    # evaluate on the training set\n",
    "    y_pred =dtc_mdl.predict(X_train)\n",
    "    mlflow.log_metric(\"train_accuracy\", accuracy_score(y_train, y_pred))\n",
    "    mlflow.log_metric(\"train_precision\", precision_score(y_train, y_pred) )\n",
    "    mlflow.log_metric(\"train_recall\", recall_score(y_train, y_pred) )\n",
    "    mlflow.log_metric(\"train_f1\", f1_score(y_train, y_pred))\n",
    "\n",
    "    # evaluate on the test set\n",
    "    y_pred = dtc_mdl.predict(X_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy_score(y_test, y_pred) )\n",
    "    mlflow.log_metric(\"test_precision\", precision_score(y_test, y_pred) )\n",
    "    mlflow.log_metric(\"test_recall\", recall_score(y_test, y_pred) )\n",
    "    mlflow.log_metric(\"test_f1\", f1_score(y_test, y_pred) )\n",
    "\n",
    "    # MODEL EVALUATION (From Analytics Masters Degree)\n",
    "\n",
    "    eval_data = X_test \n",
    "    eval_data[target_col] = y_test \n",
    "\n",
    "    mlflow.evaluate(\n",
    "        model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets = target_col,\n",
    "        model_type = \"classifier\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6498fd41-56cd-46a6-b9dd-70cc56a13f74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can access all model details using the run.info class\n",
    "run.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68d9e5ca-bbad-495d-8cf1-624991b3754f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Log Model Artifacts\n",
    "In addition to logging parameters, metrics, and the model itself, we can also log artifacts-any files or data relevant to the run. Let's set up an MLflow client to log artifacts after the run is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c2c9dbc-55cb-4fac-8a12-420149e50ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4cb6c3d-5ca3-4b65-a57e-29a32bbf5a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log Confusion Matrix\n",
    "\n",
    "The confusion matrix is a useful tool to visualize the classification performance of the model. It provides insights into the true positive, true negative, false positive, and false negative predictions.\n",
    "\n",
    "Let's create the confusion matrix and log it with MLflow using `log_figure` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183e17aa-ca33-445d-8cfa-d6e8dc14d241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Computing the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "# Creating a figure object and axes for the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plotting the confusion matrix using the created axes\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[1, 0])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "# Setting the title of the plot\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Now 'fig' can be used with MLFlow's log_figure function\n",
    "client.log_figure(run.info.run_id, figure=fig, artifact_file=\"confusion_matrix.png\")\n",
    "\n",
    "# Showing the plot here for demonstration\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78391a2f-8d24-460a-adaa-2f80b2dfb8a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log Feature Importance\n",
    "\n",
    "Now, let's examine and log the resulting model. We'll extract and plot the feature importances inferred from the Decision Tree model to understand which data features are most\n",
    "critical for successful prediction.\n",
    "\n",
    "Similar to the previous figure, we will use log_figure function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a22ef0a5-c6cc-4c05-b691-a974e45f68e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieving feature importances\n",
    "feature_importances = dtc_mdl.feature_importances_\n",
    "feature_names = X_train.columns.to_list()\n",
    "\n",
    "# Plotting the feature importances\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_pos = np.arange(len(feature_names) )\n",
    "ax.bar(y_pos, feature_importances, align='center', alpha=0.7)\n",
    "ax. set_xticks(y_pos)\n",
    "ax. set_xticklabels(feature_names, rotation=45)\n",
    "ax.set_ylabel('Importance')\n",
    "ax.set_title('Feature Importances in Decision Tree Classifier')\n",
    "\n",
    "# log to mlflow\n",
    "client.log_figure(run.info.run_id, figure=fig, artifact_file=\"feature_importances.png\")\n",
    "\n",
    "# display here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba51eea6-9c0c-468b-9b03-eb693c334d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log Tree Structure\n",
    "\n",
    "Decision trees make splitting decisions on different features at different critical values, and visualizing the tree structure helps us understand the decision logic. We'll plot the\n",
    "branching tree structure for better interpretation.\n",
    "\n",
    "We can get the tree in text format or as a graph. To log the text format we will use log_artifact function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e980699-2fd9-4d96-bc2c-fc4b1b4b039e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The fitted DecisionTreeClassifier model has {dtc_mdl.tree_.node_count} nodes and is up to {dtc_mdl.tree_.max_depth} levels deep.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194cc6a7-f57f-47dd-9d04-868d570a4990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "text_representation = export_text(dtc_mdl, feature_names=feature_names)\n",
    "print(text_representation)\n",
    "\n",
    "# save this to a local file\n",
    "tree_struct_filename = \"tree_structure.txt\"\n",
    "with open(tree_struct_filename,'w') as f:\n",
    "    f.write(text_representation)\n",
    "\n",
    "# log it to mlflow\n",
    "client.log_artifact(run.info.run_id, tree_struct_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "339b8c24-cdf9-4fa2-aee6-deea7781d9c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# plot the tree structure\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plot_tree(dtc_mdl,\n",
    "    feature_names=feature_names,\n",
    "    max_depth=2,\n",
    "    class_names=['0', '1'],\n",
    "    filled=True,\n",
    "    ax=ax)\n",
    "ax.set_title('Decision Tree Structure')\n",
    "\n",
    "# log it to mlflow\n",
    "client.log_figure(run.info.run_id, fig, \"decision_tree_structure.png\")\n",
    "\n",
    "# display it here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613146ef-877b-4117-9285-3ecb6f195984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FeatureStore_Diabetes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
